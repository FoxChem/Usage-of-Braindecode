{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T09:29:41.822598Z",
     "start_time": "2025-06-24T09:29:35.343391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from braindecode.datasets import MOABBDataset\n",
    "from braindecode.preprocessing import preprocess, Preprocessor, create_windows_from_events, exponential_moving_standardize\n",
    "from braindecode.models import EEGNetv4\n",
    "from braindecode.classifier import EEGClassifier\n",
    "from braindecode.util import set_random_seeds\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Subset\n",
    "from skorch.callbacks import LRScheduler, Checkpoint, EarlyStopping\n",
    "from skorch.helper import predefined_split\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "id": "5e19dc82bbc3c99f",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "set_random_seeds(seed=42, cuda=torch.cuda.is_available())\n",
    "dataset = MOABBDataset(dataset_name='BNCI2014001', subject_ids=[1])"
   ],
   "id": "8696891c4b61ddea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#预处理\n",
    "preprocessors = [\n",
    "    Preprocessor('pick_types', eeg=True, meg=False, stim=False),\n",
    "    Preprocessor('filter', l_freq=4., h_freq=38.),\n",
    "    Preprocessor(exponential_moving_standardize, factor_new=0.001, init_block_size=1000)\n",
    "]\n",
    "preprocess(dataset, preprocessors)"
   ],
   "id": "54d0de0bd8158d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 创建窗口\n",
    "windows_dataset = create_windows_from_events(\n",
    "    dataset, trial_start_offset_samples=0, trial_stop_offset_samples=0, preload=True\n",
    ")\n",
    "\n",
    "print(f'Windows: {len(windows_dataset)}')\n",
    "print(f'Classes: {np.unique(windows_dataset.get_metadata().target)}')"
   ],
   "id": "430cd2b197c6fae8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 划分\n",
    "N = len(windows_dataset)\n",
    "inds = np.arange(N)\n",
    "\n",
    "train_inds, valid_inds = train_test_split(\n",
    "    inds,\n",
    "    test_size=0.2,\n",
    "    stratify=windows_dataset.get_metadata().target,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_set = Subset(windows_dataset, train_inds)\n",
    "valid_set = Subset(windows_dataset, valid_inds)"
   ],
   "id": "f596f866bd9bde8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# EEGNet 模型\n",
    "X, y, metadata = windows_dataset[0]\n",
    "in_chans = X.shape[0]\n",
    "input_window_samples = X.shape[1]\n",
    "n_classes = len(np.unique(windows_dataset.get_metadata().target))\n",
    "\n",
    "model = EEGNetv4(\n",
    "    in_chans=in_chans,\n",
    "    n_classes=n_classes,\n",
    "    input_window_samples=input_window_samples\n",
    ").to(device)"
   ],
   "id": "e97adcd9040ebf09"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 封装\n",
    "# 自动保存 & 自动加载最优模型\n",
    "checkpoint = Checkpoint(\n",
    "    monitor='valid_acc_best',  # 自定义指标名\n",
    "    f_params='best_model.pt',\n",
    "    load_best=True  # 训练后自动加载\n",
    ")\n",
    "\n",
    "# 学习率调度器（逐步下降）\n",
    "lr_scheduler = LRScheduler(\n",
    "    policy=CosineAnnealingLR,\n",
    "    T_max=50  # T_max=总 epochs\n",
    ")\n",
    "\n",
    "clf = EEGClassifier(\n",
    "    model,\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    optimizer__lr=0.01,\n",
    "    batch_size=32,  # 初始 batch size，可后面 grid search\n",
    "    train_split=predefined_split(valid_set),  # 用手动验证集\n",
    "    callbacks=[\n",
    "        'accuracy',\n",
    "        checkpoint,  # 保存最佳模型\n",
    "        lr_scheduler\n",
    "    ],\n",
    "    device=device,\n",
    "    classes=np.unique(windows_dataset.get_metadata().target)\n",
    ")"
   ],
   "id": "4120f7d30e914311"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 训练&测试\n",
    "clf.fit(train_set, y=None, epochs=50)\n",
    "# 验证集\n",
    "y_valid_true = [y for _, y, _ in valid_set]\n",
    "y_valid_pred = clf.predict(valid_set)\n",
    "print(f'✅ Final valid accuracy: {accuracy_score(y_valid_true, y_valid_pred):.4f}')"
   ],
   "id": "69f671e1a8b55c42"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 可视化\n",
    "# 自动记录了 valid_acc_best\n",
    "history = pd.DataFrame(clf.history)\n",
    "plt.plot(history['epoch'], history['train_accuracy'], label='Train')\n",
    "plt.plot(history['epoch'], history['valid_accuracy'], label='Valid')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title('Train/Valid Accuracy with LR Scheduler & Checkpoint')\n",
    "plt.show()\n",
    "plt.plot(history['epoch'], history['train_loss'], label='Train')\n",
    "plt.plot(history['epoch'], history['valid_loss'], label='Valid')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title('Train/Valid Loss')\n",
    "plt.show()\n",
    "print(f\"Best valid acc (from history): {max(history['valid_accuracy']):.4f}\")"
   ],
   "id": "4c5c366ca96a4f56"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from skorch.helper import SliceDataset\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 把 EEGClassifier 用到 GridSearchCV，需要传 X, y\n",
    "y_train = [y for _, y, _ in train_set]\n",
    "\n",
    "param_grid = {\n",
    "    'batch_size': [16, 32, 64]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    clf,\n",
    "    param_grid,\n",
    "    refit=False,  # 不重新 fit，防止重复\n",
    "    scoring='accuracy',\n",
    "    cv=2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 用 skorch 的 SliceDataset 兼容\n",
    "X_train = SliceDataset(train_set, idx=0)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Grid search results:\")\n",
    "print(gs.cv_results_)\n",
    "print(f\"Best batch size: {gs.best_params_['batch_size']}\")\n",
    "results = pd.DataFrame(gs.cv_results_)\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.errorbar(\n",
    "    results['param_batch_size'].astype(int),\n",
    "    results['mean_test_score'],\n",
    "    yerr=results['std_test_score'],\n",
    "    fmt='-o', capsize=5\n",
    ")\n",
    "plt.title('Grid Search Result: Batch Size vs CV Accuracy')\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('Mean CV Accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "a0739e76db36f5ee"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
